package main

import (
	"bufio"
	"encoding/xml"
	"fmt"
	"io"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strings"

	"github.com/meilisearch/meilisearch-go"
)

// Global Configuration
const (
	MeiliURL    = "http://localhost:7700"
	MeiliKey    = "masterKey123"
	IndexName   = "ontology"
	OboPurlBase = "http://purl.obolibrary.org/obo/"
	BatchSize   = 2000
)

type TermDoc struct {
	ID       string   `json:"id"`
	Label    string   `json:"label"`
	En       string   `json:"en"`
	Ja	 string   `json:"ja"`
	Uri      string   `json:"uri"`
	Synonyms []string `json:"synonyms"`
	Ontology string   `json:"ontology"`
}

// è¨­å®š: XSDã‚’è¿½åŠ 
var ontologyConfig = map[string]string{
//	"pato.obo":             "ontology",
//	"ro.obo":               "ontology",
//	"envo.obo":             "ontology",
//	"ncbitaxon.obo":        "classification",
	"tdwg_dwc_simple.xsd": "dwc", // â˜…XSDãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ 
}

func main() {
	log.Println("ðŸš€ Starting Multi-Index Indexer (XSD Support)")

	client := meilisearch.New(MeiliURL, meilisearch.WithAPIKey(MeiliKey))

	if err := RunBatchIndexer(client); err != nil {
		log.Fatalf("âŒ Indexing failed: %v", err)
	}

	log.Println("âœ… All indexing processes completed successfully.")
}

func RunBatchIndexer(client meilisearch.ServiceManager) error {
	// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆæœŸè¨­å®š
	indices := []string{"ontology", "classification", "dwc"}
	for _, idxName := range indices {
		client.Index(idxName).UpdateIndex(&meilisearch.UpdateIndexRequestParams{
			PrimaryKey: "id",
		})
		filterAttributes := []string{"ontology", "label", "id"}
		convertedAttributes := make([]interface{}, len(filterAttributes))
		for i, v := range filterAttributes {
			convertedAttributes[i] = v
		}
		client.Index(idxName).UpdateFilterableAttributes(&convertedAttributes)
		log.Printf("âš™ï¸  Configured index: %s", idxName)
	}

	dwcJaMap, err := loadJapanesXML("data/ontologies/tdwg_dwc_simple_ja.xsd")
	if err != nil {
		log.Printf("âš ï¸  Failed to load dwc_ja.xml: %v (continuing without JA)", err)
		dwcJaMap = make(map[string]string)
	} else {
		log.Printf("âœ… Loaded %d Japanese terms from dwc_ja.xml", len(dwcJaMap))
	}

	// ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
	for filename, targetIndex := range ontologyConfig {
		filePath := filepath.Join("data", "ontologies", filename)
		if _, err := os.Stat(filePath); os.IsNotExist(err) {
			// log.Printf("âš ï¸  File not found: %s (skipping)", filename)
			continue
		}

		log.Printf("ðŸ“ Processing %s -> Index: [%s]", filename, targetIndex)

		var count int
		var err error

		// æ‹¡å¼µå­ã§ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’åˆ‡ã‚Šæ›¿ãˆ
		if strings.HasSuffix(filename, ".xsd") {
			// XSDãƒ‘ãƒ¼ã‚µãƒ¼ (DwCç”¨)
			count, err = processXsdFile(client, filePath, targetIndex)
		} else {
			// OBOãƒ‘ãƒ¼ã‚µãƒ¼ (ãã®ä»–ç”¨)
			count, err = processFileInBatches(client, filePath, targetIndex)
		}

		if err != nil {
			return fmt.Errorf("failed to process %s: %w", filename, err)
		}
		log.Printf("   -> Finished %s. Total indexed: %d terms.", filename, count)
	}

	return nil
}

// ---------------------------------------------------
// XSD Parser for Darwin Core
// ---------------------------------------------------

// XSDã®æ§‹é€ å®šç¾© (å¿…è¦ãªéƒ¨åˆ†ã®ã¿)
type XsElement struct {
	Ref string `xml:"ref,attr"`
}

type XsAll struct {
	Elements []XsElement `xml:"element"`
}

type XsComplexType struct {
	All XsAll `xml:"all"`
}

type XsSchema struct {
	Elements []struct {
		Name        string        `xml:"name,attr"`
		ComplexType XsComplexType `xml:"complexType"`
	} `xml:"element"`
}

func processXsdFile(client meilisearch.ServiceManager, filePath, targetIndex string) (int, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return 0, err
	}
	defer file.Close()

	byteValue, err := io.ReadAll(file)
	if err != nil {
		return 0, fmt.Errorf("failed to read file: %w", err)
	}

	var schema XsSchema
	// åå‰ç©ºé–“ã‚’ç„¡è¦–ã™ã‚‹ãŸã‚ã«ã€æ§‹é€ ä½“ã‚¿ã‚°ã§ã¯å˜ç´”ãªåå‰ã ã‘æŒ‡å®š
	// encoding/xml ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§åå‰ç©ºé–“ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ç„¡è¦–ã—ã¦ãƒžãƒƒãƒãƒ³ã‚°ã—ã¦ãã‚Œã‚‹
	if err := xml.Unmarshal(byteValue, &schema); err != nil {
		return 0, fmt.Errorf("xml unmarshal error: %w", err)
	}

	var batch []TermDoc
	totalCount := 0

	// SimpleDarwinRecord ã®ä¸­èº«ã‚’æŽ¢ã™
	for _, rootElem := range schema.Elements {
		if rootElem.Name == "SimpleDarwinRecord" {
			for _, elem := range rootElem.ComplexType.All.Elements {
				// ref="dwc:occurrenceID" ã®ã‚ˆã†ãªå½¢å¼
				ref := elem.Ref
				if ref == "" { continue }
				
				// "dwc:occurrenceID" -> prefix="dwc", localName="occurrenceID"
				parts := strings.Split(ref, ":")
				if len(parts) != 2 { continue }
				
				prefix := parts[0]
				localName := parts[1]
				
				// IDç”Ÿæˆ
				safeID := prefix + "_" + localName // dwc_occurrenceID
				
				enLabel := desc.Label
				if enLabel == "" {
					enLabel = localName
				}

				// â˜…æ—¥æœ¬èªžãƒ©ãƒ™ãƒ« (ãƒžãƒƒãƒ—ã‹ã‚‰æ¤œç´¢)
				jaLabel := jaMap[aboutURI]
				
				// è¡¨ç¤ºç”¨ãƒ©ãƒ™ãƒ«: æ—¥æœ¬èªžãŒã‚ã‚Œã°ãã£ã¡ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°è‹±èªž
				displayLabel := enLabel
				if jaLabel != "" {
					displayLabel = jaLabel
				}

				// URIç”Ÿæˆ (æ¨™æº–çš„ãªDwCã®URIã‚’æŽ¨æ¸¬)
				uri := ""
				if prefix == "dwc" {
					uri = "http://rs.tdwg.org/dwc/terms/" + localName
				} else if prefix == "dc" {
					uri = "http://purl.org/dc/elements/1.1/" + localName
				} else if prefix == "dcterms" {
					uri = "http://purl.org/dc/terms/" + localName
				}

				doc := TermDoc{
					ID:       safeID,
					Label:    displayLabel, // XSDã«ã¯ãƒ©ãƒ™ãƒ«ãŒãªã„ã®ã§ãƒ­ãƒ¼ã‚«ãƒ«åã‚’ä½¿ã†
					En:       enLabel,
					Ja:       jaLabel,
					Uri:      uri,
					Ontology: "DwC", // prefixã«ã‚ˆã£ã¦å¤‰ãˆã¦ã‚‚è‰¯ã„
					Synonyms: []string{ref}, // "dwc:occurrenceID" ã‚‚æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«
				}

				if jaLabel != "" {
					doc.Synonyms = append(doc.Synonyms, jaLabel)
				}

				batch = append(batch, doc)

				if len(batch) >= BatchSize {
					if _, err := client.Index(targetIndex).AddDocuments(batch, nil); err != nil {
						return totalCount, err
					}
					totalCount += len(batch)
					batch = []TermDoc{}
				}
			}
		}
	}

	// æ®‹ã‚Šã‚’é€ä¿¡
	if len(batch) > 0 {
		if _, err := client.Index(targetIndex).AddDocuments(batch, nil); err != nil {
			return totalCount, err
		}
		totalCount += len(batch)
	}

	return totalCount, nil
}

// ---------------------------------------------------
// OBO Parser (Existing)
// ---------------------------------------------------
func processFileInBatches(client meilisearch.ServiceManager, filePath, targetIndex string) (int, error) {
	// ... (OBOãƒ‘ãƒ¼ã‚µãƒ¼ã®ä¸­èº«ã¯å¤‰æ›´ãªã—ã€ãã®ã¾ã¾æ®‹ã™) ...
	file, err := os.Open(filePath)
	if err != nil {
		return 0, err
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	buf := make([]byte, 0, 64*1024)
	scanner.Buffer(buf, 1024*1024)

	var batch []TermDoc
	var currentDoc *TermDoc
	totalCount := 0

	reSynonym := regexp.MustCompile(`^synonym: "([^"]+)"`)

	sendBatch := func(docs []TermDoc) error {
		if len(docs) == 0 {
			return nil
		}
		_, err := client.Index(targetIndex).AddDocuments(docs, nil)
		if err != nil {
			return fmt.Errorf("meilisearch send error: %w", err)
		}
		return nil
	}

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())

		if strings.HasPrefix(line, "[") && strings.HasSuffix(line, "]") {
			if currentDoc != nil {
				if currentDoc.Label == "" { currentDoc.Label = currentDoc.En }
				if currentDoc.ID != "" {
					batch = append(batch, *currentDoc)
				}
			}

			if len(batch) >= BatchSize {
				if err := sendBatch(batch); err != nil {
					return totalCount, err
				}
				totalCount += len(batch)
				fmt.Printf("\r      ... Indexed %d terms", totalCount)
				batch = []TermDoc{}
			}

			if line == "[Term]" {
				currentDoc = &TermDoc{Synonyms: []string{}}
			} else {
				currentDoc = nil
			}
			continue
		}

		if currentDoc == nil { continue }

		if strings.HasPrefix(line, "id: ") {
			rawID := strings.TrimPrefix(line, "id: ")
			if !strings.Contains(rawID, ":") { continue }

			safeID := strings.ReplaceAll(rawID, ":", "_")
			currentDoc.ID = safeID
			currentDoc.Uri = OboPurlBase + safeID
			
			parts := strings.Split(safeID, "_")
			if len(parts) > 0 {
				currentDoc.Ontology = parts[0]
			}

		} else if strings.HasPrefix(line, "name: ") {
			name := strings.TrimPrefix(line, "name: ")
			currentDoc.Label = name
			currentDoc.En = name
		} else if strings.HasPrefix(line, "synonym: ") {
			matches := reSynonym.FindStringSubmatch(line)
			if len(matches) > 1 {
				currentDoc.Synonyms = append(currentDoc.Synonyms, matches[1])
			}
		}
	}

	if currentDoc != nil {
		if currentDoc.Label == "" { currentDoc.Label = currentDoc.En }
		if currentDoc.ID != "" {
			batch = append(batch, *currentDoc)
		}
	}
	if len(batch) > 0 {
		if err := sendBatch(batch); err != nil {
			return totalCount, err
		}
		totalCount += len(batch)
		fmt.Printf("\r      ... Indexed %d terms (Final flush)\n", totalCount)
	} else {
		fmt.Println()
	}

	return totalCount, scanner.Err()
}
