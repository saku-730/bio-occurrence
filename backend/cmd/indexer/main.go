package main

import (
	"bufio"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strings"

	"github.com/meilisearch/meilisearch-go"
)

// Global Configuration
const (
	MeiliURL    = "http://localhost:7700"
	MeiliKey    = "masterKey123"
	IndexName   = "ontology"
	OboPurlBase = "http://purl.obolibrary.org/obo/"
	BatchSize   = 2000 // â˜…2000ä»¶ã”ã¨ã«é€ä¿¡ã™ã‚‹è¨­å®š
)

// TermDoc struct for Meilisearch
type TermDoc struct {
	ID       string   `json:"id"`
	Label    string   `json:"label"`
	En       string   `json:"en"`
	Uri      string   `json:"uri"`
	Synonyms []string `json:"synonyms"`
	Ontology string   `json:"ontology"`
}

// ãƒ•ã‚¡ã‚¤ãƒ«åã¨ç™»éŒ²å…ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å¯¾å¿œè¡¨
var ontologyConfig = map[string]string{
	"pato.obo":      "ontology",
	"ro.obo":        "ontology",
	"envo.obo":      "ontology",
	"ncbitaxon.obo": "classification",
}

func main() {
	log.Println("ğŸš€ Starting Multi-Index OBO Indexer")

	client := meilisearch.New(MeiliURL, meilisearch.WithAPIKey(MeiliKey))

	if err := RunBatchIndexer(client); err != nil {
		log.Fatalf("âŒ Indexing failed: %v", err)
	}

	log.Println("âœ… All indexing processes completed successfully.")
}

func RunBatchIndexer(client meilisearch.ServiceManager) error {
	// ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š
	indices := []string{"ontology", "classification"}
	for _, idxName := range indices {
		client.Index(idxName).UpdateIndex(&meilisearch.UpdateIndexRequestParams{
			PrimaryKey: "id",
		})
		filterAttributes := []string{"ontology", "label", "id"}
		convertedAttributes := make([]interface{}, len(filterAttributes))
		for i, v := range filterAttributes {
			convertedAttributes[i] = v
		}
		client.Index(idxName).UpdateFilterableAttributes(&convertedAttributes)
		log.Printf("âš™ï¸  Configured index: %s", idxName)
	}

	// ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
	for filename, targetIndex := range ontologyConfig {
		filePath := filepath.Join("data", "ontologies", filename)
		if _, err := os.Stat(filePath); os.IsNotExist(err) {
			log.Printf("âš ï¸  File not found: %s (skipping)", filename)
			continue
		}

		log.Printf("ğŸ“ Processing %s -> Index: [%s]", filename, targetIndex)
		count, err := processFileInBatches(client, filePath, targetIndex)
		if err != nil {
			return fmt.Errorf("failed to process %s: %w", filename, err)
		}
		log.Printf("   -> Finished %s. Total indexed: %d terms.", filename, count)
	}

	return nil
}

// ---------------------------------------------------
// Streaming OBO Parser & Batch Sender
// ---------------------------------------------------

func processFileInBatches(client meilisearch.ServiceManager, filePath, targetIndex string) (int, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return 0, err
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	buf := make([]byte, 0, 64*1024)
	scanner.Buffer(buf, 1024*1024) // é•·ã„è¡Œã«å¯¾å¿œ

	var batch []TermDoc
	var currentDoc *TermDoc
	totalCount := 0

	reSynonym := regexp.MustCompile(`^synonym: "([^"]+)"`)

	// ãƒãƒƒãƒé€ä¿¡ãƒ˜ãƒ«ãƒ‘ãƒ¼
	sendBatch := func(docs []TermDoc) error {
		if len(docs) == 0 {
			return nil
		}
		_, err := client.Index(targetIndex).AddDocuments(docs, nil)
		if err != nil {
			return fmt.Errorf("meilisearch send error: %w", err)
		}
		return nil
	}

	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())

		// â˜…ä¿®æ­£: [Term] ã ã‘ã§ãªã [Typedef] ãªã©å…¨ã¦ã®ãƒ–ãƒ­ãƒƒã‚¯é–‹å§‹ã‚’æ¤œçŸ¥
		if strings.HasPrefix(line, "[") && strings.HasSuffix(line, "]") {
			// ç›´å‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Œã°ç¢ºå®šã—ã¦ãƒãƒƒãƒã«è¿½åŠ 
			if currentDoc != nil {
				if currentDoc.Label == "" { currentDoc.Label = currentDoc.En }
				// IDãŒã‚ã‚‹æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿è¿½åŠ 
				if currentDoc.ID != "" {
					batch = append(batch, *currentDoc)
				}
			}

			// ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’è¶…ãˆãŸã‚‰é€ä¿¡ (é€”ä¸­çµŒé)
			if len(batch) >= BatchSize {
				if err := sendBatch(batch); err != nil {
					return totalCount, err
				}
				totalCount += len(batch)
				fmt.Printf("\r      ... Indexed %d terms", totalCount)
				batch = []TermDoc{} // ãƒãƒƒãƒã‚¯ãƒªã‚¢
			}

			// æ–°ã—ã„ãƒ–ãƒ­ãƒƒã‚¯ã®é–‹å§‹
			if line == "[Term]" {
				currentDoc = &TermDoc{Synonyms: []string{}}
			} else {
				// [Typedef] ãªã©ä¸è¦ãªãƒ–ãƒ­ãƒƒã‚¯ã®å ´åˆã¯ nil ã«ã—ã¦ã‚¹ã‚­ãƒƒãƒ—
				currentDoc = nil
			}
			continue
		}

		// currentDocãŒãªã„ï¼ˆTermãƒ–ãƒ­ãƒƒã‚¯å¤–ï¼‰ãªã‚‰èª­ã¿é£›ã°ã™
		if currentDoc == nil {
			continue
		}

		// å±æ€§ã®ãƒ‘ãƒ¼ã‚¹
		if strings.HasPrefix(line, "id: ") {
			rawID := strings.TrimPrefix(line, "id: ")
			if !strings.Contains(rawID, ":") { continue }

			safeID := strings.ReplaceAll(rawID, ":", "_")
			currentDoc.ID = safeID
			currentDoc.Uri = OboPurlBase + safeID
			
			parts := strings.Split(safeID, "_")
			if len(parts) > 0 {
				currentDoc.Ontology = parts[0]
			}
		} else if strings.HasPrefix(line, "name: ") {
			name := strings.TrimPrefix(line, "name: ")
			currentDoc.Label = name
			currentDoc.En = name
		} else if strings.HasPrefix(line, "synonym: ") {
			matches := reSynonym.FindStringSubmatch(line)
			if len(matches) > 1 {
				currentDoc.Synonyms = append(currentDoc.Synonyms, matches[1])
			}
		}
	}

	// â˜…é‡è¦: ãƒ«ãƒ¼ãƒ—çµ‚äº†å¾Œã€æœ€å¾Œã®1ä»¶ã‚’ãƒãƒƒãƒã«è¿½åŠ 
	if currentDoc != nil {
		if currentDoc.Label == "" { currentDoc.Label = currentDoc.En }
		if currentDoc.ID != "" {
			batch = append(batch, *currentDoc)
		}
	}

	// â˜…é‡è¦: ãƒãƒƒãƒã«æ®‹ã£ã¦ã„ã‚‹ç«¯æ•°ï¼ˆä¾‹: 3200ä»¶ä¸­ã®200ä»¶ï¼‰ã‚’é€ä¿¡
	log.Println("batch rest")
	if len(batch) > 0 {
		if err := sendBatch(batch); err != nil {
			return totalCount, err
		}
		totalCount += len(batch)
		fmt.Printf("\r      ... Indexed %d terms (Final flush)\n", totalCount)
	} else {
		fmt.Println() // æ”¹è¡Œã®ã¿
	}

	return totalCount, scanner.Err()
}
